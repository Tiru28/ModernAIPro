# -*- coding: utf-8 -*-
"""First LLM

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14I39CnLNSZYekRVzArEuE2Q1Sryhov2i
"""

!pip install -U -q  langchain-groq

from langchain_groq import ChatGroq
from google.colab import userdata
llm_groq = ChatGroq(model_name="deepseek-r1-distill-llama-70b", api_key=userdata.get("GROQ_API_KEY"), temperature=0.7)
llm_groq2 = ChatGroq(model_name="openai/gpt-oss-120b", api_key=userdata.get("GROQ_API_KEY"), temperature=0.7)

ai_mesg = llm_groq.invoke("When was shah rukh khan born")
print(ai_mesg.content)

ai_mesg = llm_groq2.invoke("When was shah rukh khan born")
print(ai_mesg.content)

ai_mesg = llm_groq.invoke("Write me a random COBOL code that would work in a dinosaur bank. Answer in 10 sentences")
print(ai_mesg.content)

ai_mesg.response_metadata["token_usage"]

ai_mesg = llm_groq.invoke("Tell me what I asked earlier")
print(ai_mesg.content)